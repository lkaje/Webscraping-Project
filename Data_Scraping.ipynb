{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with advice from Chris\n",
    "# define function to scrape 1000 posts from a given subreddit\n",
    "def get_data(subreddit):\n",
    "    base_url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "    data_list = []\n",
    "    daytime = None\n",
    "    while len(data_list) < 10:\n",
    "        req = requests.get(\n",
    "            base_url,\n",
    "            params={\n",
    "                'subreddit': subreddit,\n",
    "                'size': 100,\n",
    "                'before': daytime\n",
    "            }\n",
    "        )\n",
    "        data = req.json()\n",
    "        posts = data['data']\n",
    "        try:\n",
    "            daytime= posts[99]['created_utc']\n",
    "            data_list.append(posts)\n",
    "            time.sleep(3)\n",
    "        except:\n",
    "            break\n",
    "    new_list= []\n",
    "    for data in data_list:\n",
    "        new_list += data\n",
    "    data_frame = pd.DataFrame(new_list)\n",
    "    data_frame = data_frame[['subreddit', 'selftext', 'title']]\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape 'AnimalCrossing'\n",
    "AnimalCrossing = get_data('AnimalCrossing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine columns\n",
    "AnimalCrossing['text'] = AnimalCrossing['selftext']+ AnimalCrossing['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AnimalCrossing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write dataset to csv\n",
    "AnimalCrossing.to_csv('data/AnimalCrossing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape 'acturnips'\n",
    "acturnips = get_data('acturnips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine columns\n",
    "acturnips['text'] = acturnips['selftext']+ acturnips['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acturnips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write dataset to csv\n",
    "acturnips.to_csv('data/acturnips.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
